# ü¶ç Alfred V2 ‚Äî Modular, Hybrid-Intent Building-Aware Search Assistant

Alfred is an intelligent, Streamlit-based search assistant for the University of Bristol's Campus Innovation Technology team.

It provides **multi-domain, building-aware search** across:
- Building Management Systems (BMS)
- Fire Risk Assessments (FRAs)
- Planon property data (conditions, areas, metadata)
- Maintenance requests and job records  
- General RAG / semantic search across documentation

Powered by:
‚úÖ OpenAI embeddings  
‚úÖ Pinecone vector search  
‚úÖ A hybrid **rule-based + ML intent classifier** pipeline  

---

## üß† Intent Detection (New in V2)

Alfred V2 uses a **Hybrid Intent Routing System** with the `NLPIntentClassifier`:

### ‚úÖ `intent_classifier.py` - NLPIntentClassifier
A sophisticated, context-aware intent classifier using **Hugging Face's SentenceTransformers** (`all-MiniLM-L6-v2`) that:

**Core Features:**
- Loads pre-trained model from local `models/all-MiniLM-L6-v2/` directory or auto-downloads from Hugging Face
- Auto-extracts zipped models at startup for convenience
- Generates and caches intent embeddings for all query types (pickled for speed in `intent_embeddings_cache.pkl`)
- Returns calibrated confidence scores using **softmax normalisation**
- Provides both semantic and pattern-based classification with automatic fallback

**Advanced Capabilities:**
- **Context-aware biasing**: Adjusts confidence scores based on `QueryContext` (detected buildings, business terms)
- **Hybrid classification**: Combines semantic similarity (70% mean + 30% max example) with pattern matching
- **Confidence threshold**: Default 0.65 threshold triggers pattern fallback for low-confidence predictions
- **Graceful degradation**: Falls back to pattern-only mode if SentenceTransformers unavailable

**Intent Training Examples:**
The classifier is trained on domain-specific examples across 6 query types:
- `CONVERSATIONAL` (greetings, help requests)
- `MAINTENANCE` (PPM, jobs, requests)
- `RANKING` (largest, top N, comparisons)
- `PROPERTY_CONDITION` (derelict, condition A-D)
- `COUNTING` (how many, count)
- `SEMANTIC_SEARCH` (BMS config, FRA process, HVAC systems)

### ‚úÖ Classification Behavior:
- If semantic confidence ‚â• 0.65 ‚Üí Uses semantic classification with context biasing
- If semantic confidence < 0.65 ‚Üí Falls back to pattern-based classification
- Context biasing adjusts scores by up to 5% based on detected buildings and business terms
- If a handler declines during negotiation, QueryManager escalates automatically

---

## üß† Core Architecture Overview

Alfred's architecture follows a **modular, layered design**:

```
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ      Streamlit UI      ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ     QueryManager       ‚îÇ
            ‚îÇ  Hybrid Intent Router  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Rule Layer ‚Üí Regex/Keyword Matching‚îÇ
       ‚îÇ ML Layer ‚Üí NLPIntentClassifier     ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         Handlers Layer                ‚îÇ
    ‚îÇ (Conversational / Property /          ‚îÇ
    ‚îÇ  Maintenance / Counting / Ranking /   ‚îÇ
    ‚îÇ  SemanticSearch)                      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   search_core package  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Key Components

| Module | Purpose |
|--------|----------|
| **`main.py`** | Streamlit entry point. Initialises cache, handles UI, logging, and session state. |
| **`intent_classifier.py`** | NLPIntentClassifier - Hugging Face SentenceTransformers model with context-aware biasing and calibrated confidence |
| **`query_manager.py`** | Routes user input to the appropriate handler using a weighted priority system. Integrates NLPIntentClassifier for hybrid intent pipeline |
| **`query_context.py`** | Encapsulates query metadata (buildings, business terms, complexity) used for context-aware classification |
| **`query_types.py`** | Enum defining all supported query intents (CONVERSATIONAL, MAINTENANCE, RANKING, etc.) |
| **`base_handler.py`** | Abstract base class for all query handlers with consistent logging and metadata extraction. |
| **Handlers Layer** | Specialised query processors implementing `can_handle()` and `handle()` methods: |
| ‚Üí `conversational_handler.py` | Responds to greetings, about queries, and small talk. |
| ‚Üí `counting_handler.py` | Handles counting queries ("How many buildings have FRAs?"). |
| ‚Üí `maintenance_handler.py` | Handles maintenance requests, jobs, and categories. |
| ‚Üí `property_handler.py` | Handles property condition and derelict building queries. |
| ‚Üí `ranking_handler.py` | Handles "largest/smallest/top" building queries. |
| ‚Üí `semantic_search_handler.py` | Fallback search handler for all remaining queries using Pinecone semantic vector retrieval + OpenAI summarisation. |
| **`search_core` package** | Unified structured + semantic retrieval engine |
| ‚Üí `search_router.py` | Unified entry point for structured and semantic searches. |
| ‚Üí `search_instructions.py` | Defines `SearchInstructions` dataclass to pass structured search intent. |
| ‚Üí `planon_search.py` | Handles property and Planon-related structured queries. |
| ‚Üí `maintenance_search.py` | Handles structured maintenance vector lookups. |
| ‚Üí `search_utils.py` | Core utilities for boosting, deduplication, and building filters. |
| **`building/utils.py`** | Comprehensive building cache, alias, and fuzzy matching utilities (centralised). |
| **`structured_queries.py`** | Rule-based structured detection for counting, ranking, maintenance, and property queries. |
| **`config/config.py`** | Global environment, API keys, and Pinecone/OpenAI configuration. |

---

## üß© Smart Query Routing

Alfred uses a **Chain of Responsibility pattern** via the `QueryManager`:

1. **Preprocessing**: Extracts buildings, business terms, and analyses query complexity
2. **Intent Classification**: NLPIntentClassifier predicts intent with confidence score
3. **Handler Selection**: Each handler declares a `priority` (lower number = higher priority)
4. **Execution**: The `QueryManager` sequentially checks each handler's `can_handle()` method
5. **Fallback**: `SemanticSearchHandler` handles all remaining unclassified queries

Example:
```text
"Hi Alfred" ‚Üí ConversationalHandler (priority: 1)
"Which buildings have maintenance requests?" ‚Üí MaintenanceHandler (priority: 2)
"Which buildings are derelict?" ‚Üí PropertyHandler (priority: 3)
"Top 10 largest buildings" ‚Üí RankingHandler (priority: 4)
"How many buildings have FRAs?" ‚Üí CountingHandler (priority: 5)
"Describe frost protection in Berkeley Square" ‚Üí SemanticSearchHandler (priority: 99)
```

---

## üß± search_core Layer

The `search_core` package provides a **unified structured + semantic retrieval system**.

### üîç `SearchInstructions`
```python
@dataclass
class SearchInstructions:
    type: str           # "semantic", "planon", "maintenance"
    query: str
    top_k: int
    building: str | None = None
    document_type: str | None = None
```

All handlers construct a `SearchInstructions` object when a search is needed.  
The router then calls the correct backend automatically:

```python
from search_core.search_router import execute
results, answer, pub_date, score_flag = execute(SearchInstructions(
    type="semantic",
    query="Fire Risk Assessment for Senate House",
    top_k=5
))
```

---

## üóùÔ∏è Building Cache & Matching

`building/utils.py` serves as the single source of truth for:

- Alias and canonical name mapping  
- Multi-index cache population  
- Fuzzy matching and validation  
- Building-specific result filtering  
- Metadata filter generation for Pinecone

Building cache initialisation runs at app startup, ensuring that all fuzzy and alias-based matches are available to every handler.

---

## üöÄ Features Summary

- **NLP Intent Classification**: Hugging Face SentenceTransformers with context-aware biasing
- **Modular Handlers**: Each query type handled by a specialised module  
- **Unified Router**: `search_core` dispatches structured vs. semantic searches
- **Session Manager**: `session_manager` Persists building context for previous user query  
- **Smart Building Cache**: Fuzzy and alias matching across multiple metadata fields  
- **OpenAI + Pinecone Integration**: RAG-style search and summarisation  
- **Logging Pipeline**: Standardised, color-coded INFO logs across all modules  
- **Error Isolation**: Each handler logs and fails gracefully without blocking others  

---

## üîß Ingestion Updates (V3)

Recent ingestion changes focus on reliability, idempotency, and observability:

**Core changes**
- **Interfaces layer** for ingestion ports (`VectorStore`, `Embedder`, `EventSink`, `IngestFileRegistry`, `JobRegistry`).
- **Redis-backed registries** for files and jobs, with status/TTL handling and atomic lease semantics.
- **File state machine** with explicit states: discovered ‚Üí processing ‚Üí upserted ‚Üí verified ‚Üí success/failed.
- **Tokenized processing**: each file run gets a `processing_token` enforced in registry state transitions.
- **VectorStore abstraction** wraps Pinecone calls and normalises error handling.
- **Embedder wrapper** owns retries/backoff/batch splitting and returns explicit index ‚Üí embedding/error mappings.
- **Unified upsert scheduling** via `VectorWriteCoordinator` (inline or worker strategy).
- **Verification paths** use the VectorStore abstraction; failures emit structured events.

**Metrics & events**
- Prometheus counters for embedding retries, batch reductions, rate limits, upsert timing, lock contention, rollback failures, and FRA supersession update outcomes (bulk vs per-item success/failure).
- JSONL event sink for ingestion summaries and verification alerts.

**Timeouts & safety**
- Configurable OpenAI timeouts (total + connect/read/write/pool) and per-file max wall-clock.
- Queue draining and failed-state recording on worker stop events.

**Redis**
- File records stored as **hashes** (not JSON blobs) with TTLs based on status.
- Job records use SETNX-style semantics to avoid duplicate supersession runs.

---

## üß∞ Developer Guide

### Environment Setup

```bash
pip install -r requirements.txt
streamlit run main.py
```

### Required Environment Variables

```
OPENAI_API_KEY=your_openai_key
PINECONE_API_KEY=your_pinecone_key
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_USERNAME=optional
REDIS_PASSWORD=optional
ANSWER_MODEL=gpt-4o-mini
DEFAULT_EMBED_MODEL=text-embedding-3-small
LOG_LEVEL=INFO
OPENAI_TIMEOUT=120
OPENAI_CONNECT_TIMEOUT=10
OPENAI_READ_TIMEOUT=60
OPENAI_WRITE_TIMEOUT=60
OPENAI_POOL_TIMEOUT=30
MAX_FILE_SECONDS=900
```

### Key Dependencies

```
# Core
streamlit==1.49.1
openai>=1.0.0
pinecone>=3.0.0

# NLP + ML
sentence-transformers==2.7.0  # Hugging Face transformers for intent classification
torch>=2.1.0                  # PyTorch backend for SentenceTransformers
textblob==0.19.0             # Spell checking
numpy>=1.24                  # Vector operations
scikit-learn>=1.4.0          # Additional ML utilities
```

### Model Files

The NLPIntentClassifier expects:
- **Local model**: `models/all-MiniLM-L6-v2/` (auto-extracted from .zip if present)
- **Cache**: `intent_embeddings_cache.pkl` (auto-generated on first run)
- **Fallback**: Auto-downloads from Hugging Face if local model not found

### Generated files

- intent_embeddings_cache.pkl is generated at runtime and should not be committed

### Logging

- Configured globally in `main.py` using `logging.basicConfig()`
- All handlers inherit logger from `BaseQueryHandler`
- Streamlit environment forced to INFO level with `STREAMLIT_LOG_LEVEL=info`

---

## üß™ Example Queries

| Query | Predicted Intent | Handler |
|--------|------------------|----------|
| "Hi Alfred" | CONVERSATIONAL | ConversationalHandler |
| "Which buildings have FRAs?" | COUNTING | CountingHandler |
| "Show maintenance for Senate House" | MAINTENANCE | MaintenanceHandler |
| "Which buildings are derelict?" | PROPERTY_CONDITION | PropertyHandler |
| "Top 5 largest buildings by area" | RANKING | RankingHandler |
| "Show the AHU logic in Senate House" | SEMANTIC_SEARCH | SemanticSearchHandler |

---

## üß© Design Principles

- **Separation of Concerns** ‚Äî Handlers only decide *what* to do; search_core decides *how*.  
- **Extensibility** ‚Äî Add new query handlers (e.g., "EnergyHandler") without touching core logic.  
- **Transparency** ‚Äî Every query logs its route and detection path.  
- **Consistency** ‚Äî All results conform to `QueryResult` schema.
- **Context Awareness** ‚Äî Intent classification considers extracted buildings and business terms.
- **Graceful Degradation** ‚Äî Falls back to pattern matching if ML model unavailable.

---

## üìù License

Internal use only ‚Äî University of Bristol Smart Technology Team  
¬© 2025 University of Bristol


